import json
from datetime import datetime
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferWindowMemory
from add_data_source import DataSource
import os
import speech_recognition as sr
from openai import OpenAI
from playsound import playsound
from dotenv import load_dotenv



load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
json_file_path = 'chat_and_response_history.json'



def save_to_json(data):
    # ê¸°ì¡´ì— íŒŒì¼ì´ ìˆìœ¼ë©´ ë‚´ìš© ì½ê³  ìƒˆ ëŒ€í™” ì¶”ê°€, ì—†ìœ¼ë©´ ìƒˆ íŒŒì¼ ìƒì„±
    try:
        with open(json_file_path, 'r', encoding="utf-8") as file:
            conversation_history = json.load(file)
    except (FileNotFoundError, json.JSONDecodeError):
        conversation_history = []


    # ìƒˆë¡œìš´ ëŒ€í™” ì¶”ê°€
    conversation_history.append(data)

    with open(json_file_path, 'w', encoding="utf-8") as file:
        json.dump(conversation_history, file, ensure_ascii=False, indent=4)


recognizer = sr.Recognizer()

# í˜ì´ì§€ ì•„ì´ì½˜ , í˜ì´ì§€ ì´ë¦„ ì„¤ì •
st.set_page_config(
    page_icon="âœ¨",
    page_title="My Helper",
)

# OpenAI API í‚¤ ì„¤ì •

# ë°ì´í„° ì†ŒìŠ¤ ì´ˆê¸°í™”
data_source = DataSource(openai_api_key)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = PromptTemplate(
    input_variables=["chat_history", "question", "retrieved_docs"],
    template="""You are an AI assistant having a conversation with a human. Use the information below to answer their question:

    Relevant information:
    {retrieved_docs}

    Chat history:
    {chat_history}

    Human: {question}
    AI:"""
)

# ëª¨ë¸ ë° ë©”ëª¨ë¦¬ ì„¤ì •
llm = ChatOpenAI(temperature=0, model_name="gpt-4o")
memory = ConversationBufferWindowMemory(memory_key="chat_history", k=3, input_key="question")
llm_chain = LLMChain(llm=llm, memory=memory, prompt=prompt)

# Streamlit UI ì„¤ì •
st.title("âœ¨Help! my examâœ¨")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!"}
    ]

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])




st.markdown(
    """
    <style>
    div.stButton > button {
        background-color: yellow; /* ë²„íŠ¼ ë°°ê²½ìƒ‰ */
        color: black; /* ë²„íŠ¼ í…ìŠ¤íŠ¸ ìƒ‰ */
        font-size: 18px; /* í°íŠ¸ í¬ê¸° */
        font-weight: bold; /* í…ìŠ¤íŠ¸ êµµê¸° */
        border: 0px solid black; /* í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ */
        border-radius: 50%; /* ë²„íŠ¼ì„ ë™ê·¸ë¼ë¯¸ë¡œ */
        padding: 20px; /* ë²„íŠ¼ ë‚´ë¶€ ì—¬ë°± (ê· ì¼í•˜ê²Œ ì„¤ì •) */
        cursor: pointer; /* ë§ˆìš°ìŠ¤ ì»¤ì„œ ë³€ê²½ */
        width: 100px; /* ë²„íŠ¼ ë„ˆë¹„ */
        height: 100px; /* ë²„íŠ¼ ë†’ì´ */
        text-align: center; /* í…ìŠ¤íŠ¸ ê°€ìš´ë° ì •ë ¬ */
    }
    div.stButton > button:hover {
        background-color: yellow; /* í˜¸ë²„ ì‹œ ë²„íŠ¼ ìƒ‰ */
        color: white; /* í˜¸ë²„ ì‹œ í…ìŠ¤íŠ¸ ìƒ‰ */
    }
    </style>
    """,
    unsafe_allow_html=True,
)

def tts_function(input_text):
    client = OpenAI(
        api_key=openai_api_key
    )

    speech_file_path = "tts_audio.mp3"

    # TTS API í˜¸ì¶œ
    response = client.audio.speech.create(
        model="tts-1",
        input=input_text,
        voice="alloy",
        response_format="mp3",
        speed=1.1,
    )

    # ìŒì„±ì„ íŒŒì¼ë¡œ ì €ì¥
    response.stream_to_file(speech_file_path)

    # ì˜¤ë””ì˜¤ ì¬ìƒ
    playsound(speech_file_path)
col1, col2 = st.columns([1,5])

with col1:
    # ë²„íŠ¼ ìƒì„± ë° ë™ì‘
    if st.button("ë§í•˜ê¸°"):
        # with sr.Microphone() as source:
        #     print("ë“£ê³  ìˆìŠµë‹ˆë‹¤!")
        #     audio = recognizer.listen(source)

            try:
                # print("ì¸ì‹ëœ í…ìŠ¤íŠ¸: " + recognizer.recognize_google(audio, language='ko-KR'))
                # user_input = recognizer.recognize_google(audio, language='ko-KR')
                user_input = "ê°‘ì‹ ì •ë³€ì´ ë­ì•¼?"



                if user_input:
                    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
                    st.session_state.messages.append({"role": "user", "content": user_input})
                    with st.chat_message("user"):
                        st.write(user_input)

                    # ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                    with st.spinner("Searching for relevant information..."):
                        retrieved_docs = data_source.similarity_search(user_input)
                        retrieved_texts = "\n".join(doc.page_content for doc in retrieved_docs)
                        print(retrieved_texts)

                    # ê²€ìƒ‰ëœ ë‚´ìš©ì„ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
                    with st.sidebar:
                        st.header("ğŸ” ê²€ìƒ‰ëœ ì •ë³´")
                        st.write(retrieved_texts)

                    # ëª¨ë¸ ì‘ë‹µ ìƒì„±
                    with st.chat_message("assistant"):
                        with st.spinner("Generating response..."):
                            ai_response = llm_chain.predict(
                                question=user_input,
                                retrieved_docs=retrieved_texts
                            )
                            st.write(ai_response)

                    # ì‘ë‹µ ì €ì¥
                    st.session_state.messages.append({"role": "assistant", "content": ai_response})

                    conversation_data = {
                        "date": current_time,
                        "user_input": user_input,
                        "response": ai_response
                    }
                    save_to_json(conversation_data)


            except sr.UnknownValueError:
                print("Google Web Speech APIê°€ ë‹¹ì‹ ì˜ ë§ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            except sr.RequestError as e:
                print(f"Google Web Speech API ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤; {e}")


# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input()

if user_input:
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    #0 ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    with st.spinner("Searching for relevant information..."):
        retrieved_docs = data_source.similarity_search(user_input)
        retrieved_texts = "\n".join(doc.page_content for doc in retrieved_docs)
        print(retrieved_texts)

        # ê²€ìƒ‰ëœ ë‚´ìš©ì„ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
    with st.sidebar:
        st.header("ğŸ” ê²€ìƒ‰ëœ ì •ë³´")
        st.write(retrieved_texts)

    # ëª¨ë¸ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("Generating response..."):
            ai_response = llm_chain.predict(
                question=user_input,
                retrieved_docs=retrieved_texts
                )
            st.write(ai_response)

            if st.session_state.tts_check:
                tts_function(ai_response)

        # ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": ai_response})

    conversation_data = {
        "date": current_time,
        "user_input": user_input,
        "response": ai_response
    }
    save_to_json(conversation_data)


with col2:
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "tts_check" not in st.session_state:
        st.session_state.tts_check = False

    if st.button("ë“£ê¸°"):
        # í˜„ì¬ ìƒíƒœë¥¼ ë°˜ëŒ€ë¡œ ì „í™˜
        st.session_state.tts_check = not st.session_state.tts_check
        st.write(st.session_state.tts_check)


