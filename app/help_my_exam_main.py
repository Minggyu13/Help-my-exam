import streamlit as st
from datetime import datetime
import json
import os
import shutil
from add_data_source import DataSource
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
from openai import OpenAI
from playsound import playsound
from dotenv import load_dotenv


load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
data_source = DataSource(openai_api_key)
# JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
JSON_FILE_PATH = "study_log.json"

st.set_page_config(
    page_icon="âœ¨",
    page_title="Help! my exam",
    layout="wide",

)


# CSSë¥¼ í†µí•´ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë³€ê²½
st.markdown(
    """
    <style>
    div.stButton > button {
        background-color: yellow; /* ë²„íŠ¼ ë°°ê²½ìƒ‰ */
        color: black; /* ë²„íŠ¼ í…ìŠ¤íŠ¸ ìƒ‰ */
        font-size: 18px; /* í°íŠ¸ í¬ê¸° */
        font-weight: bold; /* í…ìŠ¤íŠ¸ êµµê¸° */
        border: 0px solid black; /* í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ */
        border-radius: 10px; /* ë²„íŠ¼ ë‘¥ê·¼ ëª¨ì„œë¦¬ */
        padding: 10px 20px; /* ë²„íŠ¼ ë‚´ë¶€ ì—¬ë°± */
        cursor: pointer; /* ë§ˆìš°ìŠ¤ ì»¤ì„œ ë³€ê²½ */
    }
    div.stButton > button:hover {
        background-color: gold; /* í˜¸ë²„ ì‹œ ë²„íŠ¼ ìƒ‰ */
        color: white; /* í˜¸ë²„ ì‹œ í…ìŠ¤íŠ¸ ìƒ‰ */
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# ë²„íŠ¼ ìƒì„± ë° ë™ì‘


st.title("âœ¨Help! my examâœ¨")
st.subheader("ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›ğŸ’›")

if "study_notes" not in st.session_state:
    st.session_state.study_notes = []  # ì˜¤ëŠ˜ì˜ ê³µë¶€ ë‚´ìš© ë¦¬ìŠ¤íŠ¸

# JSON íŒŒì¼ ì½ê¸° í•¨ìˆ˜
def load_study_log():
    try:
        with open(JSON_FILE_PATH, "r") as file:
            return json.load(file)
    except FileNotFoundError:
        return {}

# JSON íŒŒì¼ ì“°ê¸° í•¨ìˆ˜
def save_study_log(data):
    with open(JSON_FILE_PATH, "w", encoding="utf-8") as file:
        json.dump(data, file, ensure_ascii=False, indent=4)

# ì–´ì œì˜ ê³µë¶€ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°
study_log = load_study_log()
today_date = datetime.now().strftime("%Y-%m-%d")
yesterday_notes = study_log.get(today_date, [])



# ìˆœê³µ ì‹œê°„ ê¸°ëŠ¥ :

class HelpfulAssistiveFunction:
    def __init__(self):
        pass

    @staticmethod
    def start_study_time():
        start_time = time.time()
        return start_time

    @staticmethod
    def end_study_time():
        end_time = time.time()
        return end_time



test1 = HelpfulAssistiveFunction()

import time
from streamlit_cookies_manager import EncryptedCookieManager
import streamlit as st

# ì¿ í‚¤ ê´€ë¦¬ì ì„¤ì •
cookies = EncryptedCookieManager(
    prefix="study_session",
    password="your_secure_password_here",  # ê³ ìœ  ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
)
if not cookies.ready():
    st.stop()  # ì¿ í‚¤ ì¤€ë¹„ê°€ ì•ˆ ë˜ë©´ ëŒ€ê¸°

# ì‹œê°„ í¬ë§· í•¨ìˆ˜
def format_study_duration(duration_seconds):
    hours = duration_seconds // 3600
    minutes = (duration_seconds % 3600) // 60
    seconds = duration_seconds % 60
    return f"{int(hours)}ì‹œê°„ {int(minutes)}ë¶„ {int(seconds)}ì´ˆ"

# ê³µë¶€ ì‹œì‘ ë²„íŠ¼ ì²˜ë¦¬
st.subheader("âœ¨ ìˆœê³µì‹œê°„")
col1, col2 = st.columns([1, 10])

with col1:
    if st.button("ê³µë¶€ ì‹œì‘"):
        start_time = time.time()  # í˜„ì¬ ì‹œê°„ ì €ì¥
        cookies["start_study_time"] = str(start_time)  # float ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì €ì¥
        cookies.save()  # ì¿ í‚¤ ì €ì¥
        formatted_time = time.strftime("%p %Iì‹œ %Më¶„", time.localtime(start_time))
        formatted_time_korean = formatted_time.replace("AM", "AM").replace("PM", "PN")
        st.text(f"{formatted_time_korean}")

with col2:
    if st.button("ê³µë¶€ ë"):
        end_time = time.time()  # í˜„ì¬ ì‹œê°„ ì €ì¥
        cookies["end_study_time"] = str(end_time)  # float ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì €ì¥
        cookies.save()  # ì¿ í‚¤ ì €ì¥

        # ì €ì¥ëœ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
        start_time = cookies.get("start_study_time", None)
        if start_time:
            start_time = float(start_time)  # ë¬¸ìì—´ë¡œ ì €ì¥ëœ ê°’ì„ floatë¡œ ë³€í™˜
            study_duration_seconds = end_time - start_time
            formatted_study_duration = format_study_duration(study_duration_seconds)
            formatted_end_time = time.strftime("%p %Iì‹œ %Më¶„", time.localtime(end_time))
            formatted_end_time_korean = formatted_end_time.replace("AM", "AM").replace("PM", "PM")

            st.text(f"{formatted_end_time_korean}")
            st.text(f"ìˆœê³µ: {formatted_study_duration}")
        else:
            st.text("ê³µë¶€ ì‹œì‘ ë²„íŠ¼ì„ ë¨¼ì € í´ë¦­í•˜ì„¸ìš”.")


# ì˜¤ëŠ˜ì˜ ê³µë¶€ ë‚´ìš© ê¸°ë¡
st.subheader("âœ¨ ì˜¤ëŠ˜ì˜ ê³µë¶€ ë‚´ìš©")
note = st.text_input("ê³µë¶€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”")

col3, col4 = st.columns([3  , 10])

with col3:
    if st.button("ê³µë¶€ ë‚´ìš© ì¶”ê°€ ë° ì—…ë°ì´íŠ¸"):
        if note:
            st.session_state.study_notes.append(note)
            st.success(".")
            study_log[today_date] = yesterday_notes + st.session_state.study_notes
            save_study_log(study_log)
            st.success("ê³µë¶€ ë‚´ìš©ì´ ì¶”ê°€ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ê³µë¶€ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

with col4:
    if st.button("ìš”ì•½ & í”¼ë“œë°± ë°›ê¸°"):
        file_path = 'study_log.json'

        # JSON íŒŒì¼ ì—´ê¸°
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)

        # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¡°í•©
        all_texts = []
        for date, entries in data.items():
            all_texts.extend(entries)

        # ì¡°í•©ëœ í…ìŠ¤íŠ¸ ì¶œë ¥
        today_study_content_combined_text = ' '.join(all_texts)

        # JSON íŒŒì¼ ê²½ë¡œ
        file_path = 'chat_and_response_history.json'

        # JSON íŒŒì¼ ì—´ê¸°
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)

        # user_inputê³¼ responseë¥¼ ê°ê° ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
        user_inputs = [entry['user_input'] for entry in data]
        responses = [entry['response'] for entry in data]




        model = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key, temperature=0.3)
        prompt_template = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í•˜ë£¨ í•™ìŠµ ëŒ€í™”ì™€ ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , êµì‚¬ì²˜ëŸ¼ ê±´ì„¤ì ì´ê³  ê²©ë ¤í•˜ëŠ” í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í•™ìŠµ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì¤‘ìš”í•œ ì ì„ ê°•ì¡°í•˜ê³ , ê°œì„ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì— ëŒ€í•œ ì œì•ˆì„ ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°ë¡œ ì œê³µí•©ë‹ˆë‹¤."
                ),
                (
                    "user",
                    '''ì•„ë˜ëŠ” ì˜¤ëŠ˜ì˜ í•™ìŠµ ê´€ë ¨ ëŒ€í™”ì™€ ìš”ì•½ ëŒ€ìƒ ë°ì´í„°ì…ë‹ˆë‹¤:

                        1. ì‚¬ìš©ìì™€ ì±—ë´‡ ê°„ì˜ ëŒ€í™” ê¸°ë¡:
                        - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©: {user_inputs}
                        - ì±—ë´‡ì´ ì œê³µí•œ ì‘ë‹µ: {responses}

                        2. ì˜¤ëŠ˜ ê³µë¶€í•œ ë‚´ìš© ìš”ì•½:
                        - {today_study_content_combined_text}

                        ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
                        1. ëŒ€í™” ê¸°ë¡ì—ì„œ ì¤‘ìš”í•œ ì£¼ì œë¥¼ ìš”ì•½í•˜ê³ , í•™ìŠµ íƒœë„ ë° ì ‘ê·¼ ë°©ì‹ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
                        2. ì˜¤ëŠ˜ ê³µë¶€í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¤‘ìš”í•œ í¬ì¸íŠ¸ë¥¼ ìš”ì•½í•˜ì„¸ìš”.
                        3. ì‚¬ìš©ìê°€ í•™ìŠµì„ ë” íš¨ê³¼ì ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.
                        ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
                    '''
                )
            ]
        )

        # LLMChain ìƒì„±
        chain = LLMChain(llm=model, prompt=prompt_template)

        # ë°ì´í„° ì¤€ë¹„
        # ì²´ì¸ ì‹¤í–‰

        if "response" not in st.session_state:
            st.session_state.response = ""


        response = chain.run({
            "user_inputs": user_inputs,
            "responses": responses,
            "today_study_content_combined_text": today_study_content_combined_text,
        })

        st.session_state.response = response

        if st.session_state.response:
            st.markdown('<div style="font-family: Arial; font-size: 16px; color: black; font-weight: 500;">',
                    unsafe_allow_html=True)
            st.markdown(st.session_state.response)  # Markdown ë Œë”ë§
            st.markdown('</div>', unsafe_allow_html=True)



col8, col9 = st.columns([3  , 10])
with col9:
    if st.button("ë“£ê¸°"):
        def tts_function(input_text):
            client = OpenAI(
                api_key=openai_api_key)

            speech_file_path = "tts_audio.mp3"

            # TTS API í˜¸ì¶œ
            response = client.audio.speech.create(
                model="tts-1",
                input=input_text,
                voice="alloy",
                response_format="mp3",
                speed=1.1,
            )

            # ìŒì„±ì„ íŒŒì¼ë¡œ ì €ì¥
            response.stream_to_file(speech_file_path)

            # ì˜¤ë””ì˜¤ ì¬ìƒ
            playsound(speech_file_path)


        tts_function(st.session_state.response)
# ì–´ì œì˜ ê³µë¶€ ë‚´ìš© í‘œì‹œ
st.subheader("âœ¨ History")
if yesterday_notes:
    for i, y_note in enumerate(yesterday_notes, 1):
        st.write(f"{i}. {y_note}")
else:
    st.write("ì–´ì œì˜ ê³µë¶€ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

# ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” íŒŒì¼ ì—…ë¡œë”
uploaded_files = st.file_uploader("Choose images", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

# íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ ì²˜ë¦¬
if uploaded_files:
    # ì €ì¥í•  í´ë” ê²½ë¡œ
    save_folder = "uploads"
    os.makedirs(save_folder, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

    # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    file_paths = []

    for uploaded_file in uploaded_files:
        # íŒŒì¼ ì €ì¥ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ í¬í•¨)
        save_path = os.path.join(os.getcwd(), save_folder, uploaded_file.name)  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ + uploads í´ë”

        # íŒŒì¼ì„ ë¡œì»¬ì— ì €ì¥
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        file_paths.append(save_path)

    # ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    st.write("Files saved at:", file_paths)




col6, col7 = st.columns([3,10])

with col6:
    if st.button("ë‚˜ë§Œì˜ ë°ì´í„° ì°½ê³ ì— ì¶”ê°€í•˜ê¸° "):
        encoded_image_lsit = data_source.encode_image_to_base64(file_paths)
        ocr_image_list = data_source.chatgpt_4o_prompt_template_and_invoke(encoded_image_lsit)
        chunked_list = data_source.chunking_text_splitter(ocr_image_list)
        data_source.embed_and_add_to_vectorstore(chunked_list)
        st.write("ë‚˜ë§Œì˜ ë°ì´í„° ì°½ê³ ê°€ ë§Œë“¤ì–´ì¡Œì–´ìš”!")



with col7:
    if st.button("ë‚˜ë§Œì˜ ë°ì´í„° ì°½ê³  ì‚­ì œí•˜ê¸°"):
        dir_name = "vector_db"

        if not os.path.exists(dir_name):
            print(f"ë””ë ‰í„°ë¦¬ '{dir_name}'ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


        try:
            shutil.rmtree(dir_name)  # ë¹„ì–´ ìˆì§€ ì•Šì•„ë„ ì‚­ì œ ê°€ëŠ¥
            print(f"ë””ë ‰í„°ë¦¬ '{dir_name}'ì´(ê°€) ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ë””ë ‰í„°ë¦¬ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.write("ë°ì´í„° ì°½ê³ ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")








# í”¼ë“œë°±, ë¬¸ì˜í•¨ ê¸°ëŠ¥
st.text("")
st.write('''ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ í”¼ë“œë°±ì´ ìˆëŠ” ê²½ìš° ì•„ë˜ì˜ ì´ë©”ì¼ë¡œ ì—°ë½ì„ ì£¼ì„¸ìš”! ì €í¬ëŠ” í•­ìƒ ì—´ë ¤ ìˆìŠµë‹ˆë‹¤!\n
            Email: s23055@gsm.hs.kr 

''')

